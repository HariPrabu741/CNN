{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the images and creating it to data frame\n",
    "\n",
    "images=os.listdir(\"C:/Users/USER/Downloads/cat vs dog/cat vs dog\")\n",
    "categories=[]\n",
    "for i in images:\n",
    "    category=i.split('.')[0]\n",
    "    if category=='cat':\n",
    "        categories.append(0)\n",
    "    else:\n",
    "        categories.append(1)\n",
    "        \n",
    "df=pd.DataFrame({'File':images, 'category':categories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File  category\n",
       "0     cat.1.jpg         0\n",
       "1    cat.10.jpg         0\n",
       "2   cat.100.jpg         0\n",
       "3  cat.1000.jpg         0\n",
       "4  cat.1001.jpg         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DS_Store']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking non-image file\n",
    "\n",
    "a=[i for i in df['File'] if not i.endswith('.jpg')]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8005], dtype=int64),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the index of non-image file \n",
    "\n",
    "np.where(df['File']=='_DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the non-image file\n",
    "\n",
    "df.drop(df.index[8005],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8005, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>dog.625.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>dog.3063.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>dog.3742.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>cat.2896.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>dog.2417.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File  category\n",
       "7587   dog.625.jpg         1\n",
       "6296  dog.3063.jpg         1\n",
       "7050  dog.3742.jpg         1\n",
       "2107  cat.2896.jpg         0\n",
       "5577  dog.2417.jpg         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data frames are suffled by sample function(frac=1--->100% suffle)\n",
    "\n",
    "df=df.sample(frac=1,random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,Activation,BatchNormalization,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(30,(3,3),activation='relu',input_shape=(120,120,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(75,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(120,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(220,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 118, 118, 30)      840       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 118, 118, 30)      120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 59, 59, 30)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 59, 59, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 57, 57, 75)        20325     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 57, 57, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 75)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 120)       81120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 120)       480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 120)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 13, 120)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20280)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 220)               4461820   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 220)               880       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 220)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 442       \n",
      "=================================================================\n",
      "Total params: 4,566,327\n",
      "Trainable params: 4,565,437\n",
      "Non-trainable params: 890\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_accuracy',\n",
    "                            patience=10)\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                           patience=5,\n",
    "                           factor=0.5,\n",
    "                           verbose=1,\n",
    "                           min_lr=0.00001)\n",
    "callback=[reduce_lr,early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>dog.625.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>dog.3063.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7050</th>\n",
       "      <td>dog.3742.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>cat.2896.jpg</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>dog.2417.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              File category\n",
       "7587   dog.625.jpg      Dog\n",
       "6296  dog.3063.jpg      Dog\n",
       "7050  dog.3742.jpg      Dog\n",
       "2107  cat.2896.jpg      Cat\n",
       "5577  dog.2417.jpg      Dog"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output should be in categories. If int o/p is passed to generator error occurs on class_mode.\n",
    "\n",
    "df['category']=df['category'].replace({0:'Cat',1:'Dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame is seperated to train and validation\n",
    "\n",
    "train_df,validation_df=train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6404, 2), (1601, 2))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.596.jpg</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.3011.jpg</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.2206.jpg</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog.635.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.2202.jpg</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File category\n",
       "0   cat.596.jpg      Cat\n",
       "1  cat.3011.jpg      Cat\n",
       "2  cat.2206.jpg      Cat\n",
       "3   dog.635.jpg      Dog\n",
       "4  cat.2202.jpg      Cat"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Due to shuffle index won't be in order, so reseting it\n",
    "\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog.73.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog.3279.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.242.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.1051.jpg</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog.289.jpg</td>\n",
       "      <td>Dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File category\n",
       "0    dog.73.jpg      Dog\n",
       "1  dog.3279.jpg      Dog\n",
       "2   dog.242.jpg      Dog\n",
       "3  cat.1051.jpg      Cat\n",
       "4   dog.289.jpg      Dog"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df=validation_df.reset_index(drop=True)\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6404 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating batch size, image size\n",
    "\n",
    "batch_size=15\n",
    "image_size=(120,120)\n",
    "# Creating image data generator\n",
    "\n",
    "train_gen=ImageDataGenerator(rotation_range=15,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             rescale=1./255)\n",
    "                             \n",
    "\n",
    "train_generator=train_gen.flow_from_dataframe(train_df,\n",
    "                                             directory='C:/Users/USER/Downloads/cat vs dog/cat vs dog',\n",
    "                                             x_col='File',\n",
    "                                             y_col='category',\n",
    "                                             class_mode='categorical',\n",
    "                                             target_size=image_size,\n",
    "                                             batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1601 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator=validation_gen.flow_from_dataframe(validation_df,\n",
    "                                             directory='C:/Users/USER/Downloads/cat vs dog/cat vs dog',\n",
    "                                             x_col='File',\n",
    "                                             y_col='category',\n",
    "                                             class_mode='categorical',\n",
    "                                             target_size=image_size,           \n",
    "                                             batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "426/426 [==============================] - 261s 613ms/step - loss: 0.6186 - accuracy: 0.6638 - val_loss: 0.5986 - val_accuracy: 0.6730\n",
      "Epoch 2/50\n",
      "426/426 [==============================] - 282s 662ms/step - loss: 0.5838 - accuracy: 0.6885 - val_loss: 0.7762 - val_accuracy: 0.6396\n",
      "Epoch 3/50\n",
      "426/426 [==============================] - 253s 594ms/step - loss: 0.5661 - accuracy: 0.7101 - val_loss: 0.5872 - val_accuracy: 0.7063\n",
      "Epoch 4/50\n",
      "426/426 [==============================] - 241s 565ms/step - loss: 0.5340 - accuracy: 0.7305 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 5/50\n",
      "426/426 [==============================] - 224s 526ms/step - loss: 0.5228 - accuracy: 0.7385 - val_loss: 0.5912 - val_accuracy: 0.7428\n",
      "Epoch 6/50\n",
      "426/426 [==============================] - 214s 503ms/step - loss: 0.4980 - accuracy: 0.7633 - val_loss: 0.4901 - val_accuracy: 0.7522\n",
      "Epoch 7/50\n",
      "426/426 [==============================] - 212s 498ms/step - loss: 0.4842 - accuracy: 0.7654 - val_loss: 0.4015 - val_accuracy: 0.8264\n",
      "Epoch 8/50\n",
      "426/426 [==============================] - 212s 497ms/step - loss: 0.4689 - accuracy: 0.7781 - val_loss: 0.4276 - val_accuracy: 0.8107\n",
      "Epoch 9/50\n",
      "426/426 [==============================] - 211s 496ms/step - loss: 0.4512 - accuracy: 0.7840 - val_loss: 0.4109 - val_accuracy: 0.8107\n",
      "Epoch 10/50\n",
      "426/426 [==============================] - 210s 493ms/step - loss: 0.4477 - accuracy: 0.7939 - val_loss: 0.5753 - val_accuracy: 0.7491\n",
      "Epoch 11/50\n",
      "426/426 [==============================] - 211s 494ms/step - loss: 0.4311 - accuracy: 0.8028 - val_loss: 0.5059 - val_accuracy: 0.7503\n",
      "Epoch 12/50\n",
      "426/426 [==============================] - 212s 497ms/step - loss: 0.4260 - accuracy: 0.8033 - val_loss: 0.3840 - val_accuracy: 0.8453\n",
      "Epoch 13/50\n",
      "426/426 [==============================] - 212s 497ms/step - loss: 0.4058 - accuracy: 0.8178 - val_loss: 0.4604 - val_accuracy: 0.7981\n",
      "Epoch 14/50\n",
      "426/426 [==============================] - 2204s 5s/step - loss: 0.4188 - accuracy: 0.8133 - val_loss: 0.3588 - val_accuracy: 0.8560\n",
      "Epoch 15/50\n",
      "426/426 [==============================] - 211s 494ms/step - loss: 0.3998 - accuracy: 0.8197 - val_loss: 0.6531 - val_accuracy: 0.7597\n",
      "Epoch 16/50\n",
      "426/426 [==============================] - 211s 495ms/step - loss: 0.3762 - accuracy: 0.8327 - val_loss: 0.4069 - val_accuracy: 0.8447\n",
      "Epoch 17/50\n",
      "426/426 [==============================] - 212s 496ms/step - loss: 0.3891 - accuracy: 0.8285 - val_loss: 0.4239 - val_accuracy: 0.8151\n",
      "Epoch 18/50\n",
      "426/426 [==============================] - 211s 495ms/step - loss: 0.3840 - accuracy: 0.8278 - val_loss: 0.3677 - val_accuracy: 0.8396\n",
      "Epoch 19/50\n",
      "426/426 [==============================] - 210s 493ms/step - loss: 0.3793 - accuracy: 0.8322 - val_loss: 0.3874 - val_accuracy: 0.8226\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/50\n",
      "426/426 [==============================] - 210s 494ms/step - loss: 0.3492 - accuracy: 0.8469 - val_loss: 0.3116 - val_accuracy: 0.8723\n",
      "Epoch 21/50\n",
      "426/426 [==============================] - 213s 501ms/step - loss: 0.3454 - accuracy: 0.8485 - val_loss: 0.2863 - val_accuracy: 0.8943\n",
      "Epoch 22/50\n",
      "426/426 [==============================] - 215s 505ms/step - loss: 0.3384 - accuracy: 0.8505 - val_loss: 0.2879 - val_accuracy: 0.8774\n",
      "Epoch 23/50\n",
      "426/426 [==============================] - 214s 502ms/step - loss: 0.3297 - accuracy: 0.8557 - val_loss: 0.2865 - val_accuracy: 0.8836\n",
      "Epoch 24/50\n",
      "426/426 [==============================] - 216s 506ms/step - loss: 0.3355 - accuracy: 0.8582 - val_loss: 0.3541 - val_accuracy: 0.8472\n",
      "Epoch 25/50\n",
      "426/426 [==============================] - 216s 506ms/step - loss: 0.3307 - accuracy: 0.8582 - val_loss: 0.3205 - val_accuracy: 0.8969\n",
      "Epoch 26/50\n",
      "426/426 [==============================] - 216s 507ms/step - loss: 0.3246 - accuracy: 0.8652 - val_loss: 0.3178 - val_accuracy: 0.8742\n",
      "Epoch 27/50\n",
      "426/426 [==============================] - 218s 511ms/step - loss: 0.3175 - accuracy: 0.8657 - val_loss: 0.2935 - val_accuracy: 0.8799\n",
      "Epoch 28/50\n",
      "426/426 [==============================] - 214s 502ms/step - loss: 0.3209 - accuracy: 0.8612 - val_loss: 0.3468 - val_accuracy: 0.8415\n",
      "Epoch 29/50\n",
      "426/426 [==============================] - 211s 496ms/step - loss: 0.3163 - accuracy: 0.8587 - val_loss: 0.2523 - val_accuracy: 0.8987\n",
      "Epoch 30/50\n",
      "426/426 [==============================] - 212s 498ms/step - loss: 0.3049 - accuracy: 0.8695 - val_loss: 0.3204 - val_accuracy: 0.8805\n",
      "Epoch 31/50\n",
      "426/426 [==============================] - 214s 502ms/step - loss: 0.3011 - accuracy: 0.8738 - val_loss: 0.2764 - val_accuracy: 0.8937\n",
      "Epoch 32/50\n",
      "426/426 [==============================] - 224s 526ms/step - loss: 0.3185 - accuracy: 0.8638 - val_loss: 0.3174 - val_accuracy: 0.8767\n",
      "Epoch 33/50\n",
      "426/426 [==============================] - 220s 515ms/step - loss: 0.3068 - accuracy: 0.8648 - val_loss: 0.2914 - val_accuracy: 0.8824\n",
      "Epoch 34/50\n",
      "426/426 [==============================] - 219s 514ms/step - loss: 0.3048 - accuracy: 0.8709 - val_loss: 0.2865 - val_accuracy: 0.8893\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 35/50\n",
      "426/426 [==============================] - 220s 516ms/step - loss: 0.3014 - accuracy: 0.8734 - val_loss: 0.2526 - val_accuracy: 0.8994\n",
      "Epoch 36/50\n",
      "426/426 [==============================] - 220s 516ms/step - loss: 0.2823 - accuracy: 0.8812 - val_loss: 0.3654 - val_accuracy: 0.8434\n",
      "Epoch 37/50\n",
      "426/426 [==============================] - 221s 519ms/step - loss: 0.2925 - accuracy: 0.8732 - val_loss: 0.2460 - val_accuracy: 0.9101\n",
      "Epoch 38/50\n",
      "426/426 [==============================] - 221s 520ms/step - loss: 0.2957 - accuracy: 0.8704 - val_loss: 0.2600 - val_accuracy: 0.8818\n",
      "Epoch 39/50\n",
      "426/426 [==============================] - 222s 522ms/step - loss: 0.2875 - accuracy: 0.8796 - val_loss: 0.2427 - val_accuracy: 0.9038\n",
      "Epoch 40/50\n",
      "426/426 [==============================] - 222s 521ms/step - loss: 0.2818 - accuracy: 0.8820 - val_loss: 0.2762 - val_accuracy: 0.8799\n",
      "Epoch 41/50\n",
      "426/426 [==============================] - 216s 507ms/step - loss: 0.2772 - accuracy: 0.8834 - val_loss: 0.2378 - val_accuracy: 0.9063\n",
      "Epoch 42/50\n",
      "426/426 [==============================] - 214s 503ms/step - loss: 0.2706 - accuracy: 0.8870 - val_loss: 0.2642 - val_accuracy: 0.8975\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 43/50\n",
      "426/426 [==============================] - 218s 511ms/step - loss: 0.2619 - accuracy: 0.8922 - val_loss: 0.2490 - val_accuracy: 0.9019\n",
      "Epoch 44/50\n",
      "426/426 [==============================] - 217s 510ms/step - loss: 0.2659 - accuracy: 0.8893 - val_loss: 0.2429 - val_accuracy: 0.9044\n",
      "Epoch 45/50\n",
      "426/426 [==============================] - 233s 546ms/step - loss: 0.2616 - accuracy: 0.8929 - val_loss: 0.2439 - val_accuracy: 0.9094\n",
      "Epoch 46/50\n",
      "426/426 [==============================] - 233s 547ms/step - loss: 0.2655 - accuracy: 0.8879 - val_loss: 0.2409 - val_accuracy: 0.9044\n",
      "Epoch 47/50\n",
      "426/426 [==============================] - 228s 535ms/step - loss: 0.2719 - accuracy: 0.8857 - val_loss: 0.2397 - val_accuracy: 0.9113\n",
      "Epoch 48/50\n",
      "426/426 [==============================] - 225s 527ms/step - loss: 0.2565 - accuracy: 0.8958 - val_loss: 0.2369 - val_accuracy: 0.9113\n",
      "Epoch 49/50\n",
      "426/426 [==============================] - 226s 530ms/step - loss: 0.2537 - accuracy: 0.8920 - val_loss: 0.2464 - val_accuracy: 0.9101\n",
      "Epoch 50/50\n",
      "426/426 [==============================] - 227s 533ms/step - loss: 0.2650 - accuracy: 0.8907 - val_loss: 0.2457 - val_accuracy: 0.9063\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=6404//15,\n",
    "                             epochs=50,\n",
    "                             verbose=1,\n",
    "                             callbacks=callback,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=1601//15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('catvsdog_50epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('catvsdog_50epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 118, 118, 30)      840       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 118, 118, 30)      120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 59, 59, 30)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 59, 59, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 57, 57, 75)        20325     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 57, 57, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 75)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 120)       81120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 120)       480       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 120)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 13, 120)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20280)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 220)               4461820   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 220)               880       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 220)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 442       \n",
      "=================================================================\n",
      "Total params: 4,566,327\n",
      "Trainable params: 4,565,437\n",
      "Non-trainable params: 890\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_1.jpg', 'cat_2.jpg', 'cat_3.jpg', 'dog_1.jpg', 'dog_2.jpg', 'dog_3.jpg']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=os.listdir(\"C:/Users/USER/Pictures/cat vs dog test\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(120,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog_3.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file\n",
       "0  cat_1.jpg\n",
       "1  cat_2.jpg\n",
       "2  cat_3.jpg\n",
       "3  dog_1.jpg\n",
       "4  dog_2.jpg\n",
       "5  dog_3.jpg"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.DataFrame({'file':im})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator=test_gen.flow_from_dataframe(test_df,\n",
    "                                             directory=\"C:/Users/USER/Pictures/cat vs dog test\",\n",
    "                                             x_col='file',\n",
    "                                             y_col=None,\n",
    "                                             class_mode=None,\n",
    "                                             target_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict_classes(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict']=predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat_1.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat_2.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat_3.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog_1.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog_2.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog_3.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file predict\n",
       "0  cat_1.jpg     cat\n",
       "1  cat_2.jpg     cat\n",
       "2  cat_3.jpg     dog\n",
       "3  dog_1.jpg     dog\n",
       "4  dog_2.jpg     cat\n",
       "5  dog_3.jpg     dog"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['predict']=test_df['predict'].replace({0:'cat',1:'dog'})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
